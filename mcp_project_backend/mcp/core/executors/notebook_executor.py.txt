# mcp/core/executors/notebook_executor.py
# Concrete executor for MCPs of type "Jupyter Notebook".
# This would typically use a library like Papermill to execute notebooks.

# import papermill as pm
# import nbformat # For handling notebook content if stored as cells
# import os
# import tempfile
# from .base_executor import BaseExecutor
# from mcp.core.mcp_configs import NotebookConfig
# from typing import Dict, Any

# class NotebookExecutor(BaseExecutor):
#     async def execute(self, config: NotebookConfig, inputs: Dict[str, Any]) -> Dict[str, Any]:
#         # await self._log_message(config.type, f"Executing Jupyter Notebook: {config.notebook_path_ref or 'embedded notebook'}")

#         # if not isinstance(config, NotebookConfig):
#         #     raise TypeError("Configuration for NotebookExecutor must be NotebookConfig.")

#         # input_path = None
#         # output_path = None
#         # temp_dir = tempfile.mkdtemp()

#         try:
#             # if config.notebook_path_ref:
#             #     # Assume notebook_path_ref points to a readable .ipynb file
#             #     # This path needs to be resolved (e.g., from a shared volume, S3, Git repo checkout)
#             #     input_path = config.notebook_path_ref
#             # elif config.notebook_cells:
#             #     # Create a temporary .ipynb file from cells
#             #     temp_notebook = nbformat.v4.new_notebook(cells=[
#             #         nbformat.v4.new_code_cell(cell['content']) if cell['type'] == 'code'
#             #         else nbformat.v4.new_markdown_cell(cell['content'])
#             #         for cell in config.notebook_cells
#             #     ])
#             #     input_path = os.path.join(temp_dir, "temp_notebook.ipynb")
#             #     with open(input_path, 'w', encoding='utf-8') as f:
#             #         nbformat.write(temp_notebook, f)
#             # else:
#             #     raise ValueError("Notebook configuration must provide either notebook_path_ref or notebook_cells.")

#             # output_path = os.path.join(temp_dir, "output_notebook.ipynb")

#             # await self._log_message(config.type, f"Using input notebook: {input_path}")
#             # await self._log_message(config.type, f"Parameters: {config.parameters or inputs}")

#             # # Parameters to pass to Papermill can be from config.parameters merged/overridden by runtime inputs
#             # execution_parameters = {**(config.parameters or {}), **inputs}

#             # # Execute the notebook using Papermill
#             # pm.execute_notebook(
#             #     input_path=input_path,
#             #     output_path=output_path,
#             #     parameters=execution_parameters,
#             #     # kernel_name='python3', # Specify if needed
#             #     # log_output=True, # Capture output in the notebook itself
#             #     # progress_bar=False # Typically no progress bar for programmatic execution
#             # )

#             # await self._log_message(config.type, f"Notebook execution completed. Output at: {output_path}")

#             # # Process the output notebook to extract results
#             # # This is highly dependent on how the notebook is expected to produce outputs.
#             # # E.g., specific cells tagged 'outputs', or by inspecting variables.
#             # # For simplicity, we'll assume no specific output extraction here.
#             # executed_nb = pm.read_notebook(output_path)
#             # # Example: Get value of a variable 'result' from the notebook's global scope
#             # # output_value = executed_nb.dataframe.loc[executed_nb.dataframe['name'] == 'result', 'value'].iloc[0]

#             # Return a dictionary of outputs
#             # return {"output_notebook_path": output_path, "extracted_result": "some_value"}
#             return {"status": "Notebook executed (simulated)", "parameters_received": inputs}

#         except Exception as e:
#             # await self._log_message(config.type, f"Notebook execution failed: {e}", level="ERROR")
#             # This error should be re-raised to be caught by WorkflowEngineService for proper run status update.
#             raise
#         # finally:
#             # Clean up temporary files/directory
#             # import shutil
#             # if os.path.exists(temp_dir):
#             #     shutil.rmtree(temp_dir)
